import requests
import pandas as pd
import time
import os
import csv
from bs4 import BeautifulSoup
from datetime import datetime

# --- ì„¤ì • ---
SERVICE_KEY = 
BASE_URL = "http://apis.data.go.kr/B552881/kmooc_v2_0"
LIST_URL = f"{BASE_URL}/courseList_v2_0"
DETAIL_URL = f"{BASE_URL}/courseDetail_v2_0"
SAVE_FILENAME = "kmooc_courses_final.csv"

def clean_html(raw_html):
    """HTML íƒœê·¸ë¥¼ ì œê±°í•˜ê³  ìˆœìˆ˜ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ"""
    if not raw_html or not isinstance(raw_html, str):
        return raw_html
    try:
        soup = BeautifulSoup(raw_html, "html.parser")
        # íƒœê·¸ ì‚¬ì´ ê³µë°±ì„ ì£¼ì–´ ë‹¨ì–´ê°€ ë¶™ì§€ ì•Šê²Œ ì²˜ë¦¬
        return soup.get_text(separator=' ', strip=True)
    except:
        return raw_html

def convert_date(ts):
    """ìˆ«ì íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ YYYY-MM-DD í˜•ì‹ì˜ ë¬¸ìì—´ë¡œ ë³€í™˜"""
    if not ts:
        return ts
    try:
        # ìˆ«ìë¡œë§Œ ì´ë£¨ì–´ì§„ ë¬¸ìì—´ì´ë‚˜ ìˆ«ìí˜•ì¸ ê²½ìš° ë³€í™˜
        ts_str = str(ts)
        if ts_str.isdigit():
            return datetime.fromtimestamp(int(ts)).strftime('%Y-%m-%d')
    except:
        pass
    return ts

def get_safe_json(response):
    """ì‘ë‹µì´ ìœ íš¨í•œ JSONì¸ì§€ í™•ì¸í•˜ê³  ë”•ì…”ë„ˆë¦¬ë¡œ ë°˜í™˜"""
    try:
        return response.json()
    except (ValueError, AttributeError):
        return {"error_fallback": response.text}

def save_to_csv(item_dict):
    """ë°ì´í„° í•„ë“œë¥¼ ê³ ì •í•˜ì—¬ í•œ ê±´ì”© ì•ˆì „í•˜ê²Œ ì €ì¥"""
    file_exists = os.path.isfile(SAVE_FILENAME)
    if not isinstance(item_dict, dict):
        return

    # ì €ì¥í•  í•µì‹¬ í•„ë“œ ìˆœì„œ ì •ì˜ (ERDì™€ ë§¤ì¹­í•˜ê¸° í¸í•˜ë„ë¡ ê³ ì •)
    fieldnames = [
        'id', 'shortname', 'name', 'url', 'course_image', 'org', 'org_name',
        'enrollment_start', 'enrollment_end', 'study_start', 'study_end',
        'professor', 'public_yn', 'summary', 'classfy_name', 'middle_classfy_name',
        'week', 'course_playtime', 'detail_error_raw'
    ]

    with open(SAVE_FILENAME, 'a', newline='', encoding='utf-8-sig') as f:
        # fieldnamesì— ì—†ëŠ” í‚¤ëŠ” ë¬´ì‹œí•˜ê³  ì €ì¥ (extrasaction='ignore')
        writer = csv.DictWriter(f, fieldnames=fieldnames, extrasaction='ignore')
        if not file_exists:
            writer.writeheader()
        writer.writerow(item_dict)

def main():
    # 1. ëª©ë¡ ìˆ˜ì§‘ ë‹¨ê³„
    print("ğŸš€ 1ë‹¨ê³„: ê°•ì¢Œ ëª©ë¡ ìˆ˜ì§‘ ì‹œì‘...")
    all_courses = []
    page = 1
    while True:
        params = {'ServiceKey': SERVICE_KEY, 'Page': page, 'Size': 100}
        try:
            res = requests.get(LIST_URL, params=params, timeout=15)
            data = get_safe_json(res)
            items = data.get('items', [])
            if not items: break
            
            all_courses.extend(items)
            total = data.get('header', {}).get('totalCount', 0)
            print(f"âœ… ëª©ë¡ ë¡œë“œ ì¤‘: {len(all_courses)} / {total}")
            if len(all_courses) >= int(total): break
            page += 1
            time.sleep(0.1)
        except Exception as e:
            print(f"âš ï¸ ëª©ë¡ ì˜¤ë¥˜: {e}")
            time.sleep(1); continue

    # 2. ìƒì„¸ ì •ë³´ ë³´ì™„ ë° ì •ì œ ì €ì¥
    print(f"\nğŸš€ 2ë‹¨ê³„: {len(all_courses)}ê±´ ìƒì„¸ ì •ë³´ ì •ì œ ë° ì €ì¥ ì‹œì‘...")
    
    processed_ids = set()
    if os.path.isfile(SAVE_FILENAME):
        try:
            df_check = pd.read_csv(SAVE_FILENAME, usecols=['id'])
            processed_ids = set(df_check['id'].astype(str).unique())
            print(f"â„¹ï¸ ê¸°ì¡´ íŒŒì¼ì—ì„œ {len(processed_ids)}ê±´ ë°œê²¬. ì´ì–´ì„œ ì‹œì‘í•©ë‹ˆë‹¤.")
        except: pass

    for idx, item in enumerate(all_courses):
        course_id = str(item.get('id'))
        if course_id in processed_ids: continue

        try:
            res_detail = requests.get(DETAIL_URL, params={'ServiceKey': SERVICE_KEY, 'CourseId': course_id}, timeout=15)
            detail_data = get_safe_json(res_detail)
            detail = detail_data.get('results', {})
            
            combined = item.copy()
            
            # ë°ì´í„° ì •ì œ ì ìš©
            if isinstance(detail, dict):
                combined.update(detail)
                # HTML ì œê±°
                combined['summary'] = clean_html(combined.get('summary', ''))
            else:
                combined['detail_error_raw'] = str(detail)
            
            # ë‚ ì§œ í˜•ì‹ ë³€í™˜ (ëª¨ë“  ë‚ ì§œ í•„ë“œ ëŒ€ìƒ)
            for date_key in ['enrollment_start', 'enrollment_end', 'study_start', 'study_end']:
                combined[date_key] = convert_date(combined.get(date_key))
            
            save_to_csv(combined)
            
            if (idx + 1) % 50 == 0:
                print(f"ğŸ’¾ ì§„í–‰ ìƒí™©: {idx + 1} / {len(all_courses)}")
            time.sleep(0.1)
            
        except Exception as e:
            print(f"âš ï¸ ìƒì„¸ ì‹¤íŒ¨ (ID: {course_id}): {e}")
            save_to_csv(item)
            continue

    print(f"\nìˆ˜ì§‘ ì™„ë£Œ! íŒŒì¼ëª…: {SAVE_FILENAME}")

if __name__ == "__main__":
    main()