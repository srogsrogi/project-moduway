import requests
import pandas as pd
import time
import os
import csv
from bs4 import BeautifulSoup
from datetime import datetime
from urllib.parse import unquote

# --- ì„¤ì • ---
SERVICE_KEY = 
BASE_URL = "http://apis.data.go.kr/B552881/kmooc_v2_0"
LIST_URL = f"{BASE_URL}/courseList_v2_0"
DETAIL_URL = f"{BASE_URL}/courseDetail_v2_0"

# ìŠ¤í¬ë¦½íŠ¸ ìœ„ì¹˜ ê¸°ì¤€ ì ˆëŒ€ ê²½ë¡œ ì„¤ì •
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
SAVE_FILENAME = os.path.join(BASE_DIR, "kmooc_courses_final.csv")

def clean_html(raw_html):
    """HTML íƒœê·¸ë¥¼ ì œê±°í•˜ê³  ìˆœìˆ˜ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ"""
    if not raw_html or not isinstance(raw_html, str):
        return raw_html
    try:
        soup = BeautifulSoup(raw_html, "html.parser")
        return soup.get_text(separator=' ', strip=True)
    except:
        return raw_html

def convert_date(ts):
    """ìˆ«ì íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ YYYY-MM-DD í˜•ì‹ì˜ ë¬¸ìì—´ë¡œ ë³€í™˜"""
    if not ts:
        return ts
    try:
        ts_str = str(ts)
        if ts_str.isdigit():
            return datetime.fromtimestamp(int(ts)).strftime('%Y-%m-%d')
    except:
        pass
    return ts

def get_safe_json(response):
    """ì‘ë‹µì´ ìœ íš¨í•œ JSONì¸ì§€ í™•ì¸í•˜ê³  ë”•ì…”ë„ˆë¦¬ë¡œ ë°˜í™˜"""
    try:
        return response.json()
    except (ValueError, AttributeError):
        return {"error_fallback": response.text}

def save_to_csv(item_dict):
    """ë°ì´í„° í•„ë“œë¥¼ ê³ ì •í•˜ì—¬ í•œ ê±´ì”© ì•ˆì „í•˜ê²Œ ì €ì¥"""
    file_exists = os.path.isfile(SAVE_FILENAME)
    if not isinstance(item_dict, dict):
        return

    fieldnames = [
        'id', 'shortname', 'name', 'url', 'course_image', 'org', 'org_name',
        'enrollment_start', 'enrollment_end', 'study_start', 'study_end',
        'professor', 'public_yn', 'summary', 'raw_summary', 'classfy_name', 'middle_classfy_name',
        'week', 'course_playtime', 'detail_error_raw'
    ]

    with open(SAVE_FILENAME, 'a', newline='', encoding='utf-8-sig') as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames, extrasaction='ignore')
        if not file_exists:
            writer.writeheader()
        writer.writerow(item_dict)

def main():
    # 1. ëª©ë¡ ìˆ˜ì§‘ ë‹¨ê³„
    print("ğŸš€ 1ë‹¨ê³„: ê°•ì¢Œ ëª©ë¡ ìˆ˜ì§‘ ì‹œì‘...")
    all_courses = []
    page = 1
    
    while True:
        # íŒŒë¼ë¯¸í„° ëŒ€ì†Œë¬¸ì ë° í‚¤ ì ìš©
        params = {
            'ServiceKey': SERVICE_KEY, 
            'Page': page, 
            'Size': 100
        }
        
        try:
            res = requests.get(LIST_URL, params=params, timeout=15)
            
            # ì²« í˜ì´ì§€ í˜¸ì¶œ ì‹œ ì‘ë‹µ ìƒíƒœ í™•ì¸ìš© ë””ë²„ê¹…
            if page == 1:
                if res.status_code != 200:
                    print(f"âŒ API ì—°ê²° ì‹¤íŒ¨ (Status: {res.status_code})")
                    print(f"ì‘ë‹µ ë‚´ìš©: {res.text}")
                    return
            
            data = get_safe_json(res)
            # K-MOOC APIëŠ” ë²„ì „ì— ë”°ë¼ items ë˜ëŠ” resultsì— ë°ì´í„°ë¥¼ ë‹´ìŠµë‹ˆë‹¤.
            items = data.get('items') or data.get('results') or []
            
            if not items:
                print(f"â„¹ï¸ {page}í˜ì´ì§€ì—ì„œ ìˆ˜ì§‘ì„ ì¢…ë£Œí•©ë‹ˆë‹¤. (ë°ì´í„° ì—†ìŒ)")
                break
            
            all_courses.extend(items)
            
            # totalCount ì¶”ì¶œ (ê²½ë¡œê°€ ìœ ë™ì ì¼ ìˆ˜ ìˆì–´ ì•ˆì „í•˜ê²Œ ì¶”ì¶œ)
            header = data.get('header') or data.get('meta') or {}
            total = header.get('totalCount') or header.get('count') or len(all_courses)
            
            print(f"âœ… ëª©ë¡ ë¡œë“œ ì¤‘: {len(all_courses)} / {total}")
            
            if len(all_courses) >= int(total):
                break
                
            page += 1
            time.sleep(0.2) # ì„œë²„ ë¶€í•˜ ë°©ì§€
            
        except Exception as e:
            print(f"âš ï¸ ëª©ë¡ ì˜¤ë¥˜: {e}")
            break

    # 2. ìƒì„¸ ì •ë³´ ë³´ì™„ ë° ì •ì œ ì €ì¥
    if not all_courses:
        print("âŒ ìˆ˜ì§‘ëœ ëª©ë¡ì´ ì—†ì–´ ì¢…ë£Œí•©ë‹ˆë‹¤. ì„œë¹„ìŠ¤í‚¤ í™œì„±í™” ì—¬ë¶€ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        return

    print(f"\nğŸš€ 2ë‹¨ê³„: {len(all_courses)}ê±´ ìƒì„¸ ì •ë³´ ì •ì œ ë° ì €ì¥ ì‹œì‘...")
    
    processed_ids = set()
    if os.path.isfile(SAVE_FILENAME):
        try:
            df_check = pd.read_csv(SAVE_FILENAME, usecols=['id'])
            processed_ids = set(df_check['id'].astype(str).unique())
            print(f"â„¹ï¸ ê¸°ì¡´ íŒŒì¼ì—ì„œ {len(processed_ids)}ê±´ ë°œê²¬. ì´ì–´ì„œ ì‹œì‘í•©ë‹ˆë‹¤.")
        except: pass

    for idx, item in enumerate(all_courses):
        course_id = str(item.get('id'))
        if course_id in processed_ids: continue

        try:
            res_detail = requests.get(DETAIL_URL, params={'ServiceKey': SERVICE_KEY, 'CourseId': course_id}, timeout=15)
            detail_data = get_safe_json(res_detail)
            detail = detail_data.get('results') or detail_data.get('items') or {}
            
            # ë¦¬ìŠ¤íŠ¸ë¡œ ì˜¤ëŠ” ê²½ìš° ì²« ë²ˆì§¸ ìš”ì†Œ ì„ íƒ
            if isinstance(detail, list) and len(detail) > 0:
                detail = detail[0]

            combined = item.copy()
            
            if isinstance(detail, dict):
                combined.update(detail)
                combined['raw_summary'] = combined.get('summary', '')
                combined['summary'] = clean_html(combined.get('summary', ''))
            else:
                combined['detail_error_raw'] = str(detail)
            
            for date_key in ['enrollment_start', 'enrollment_end', 'study_start', 'study_end']:
                combined[date_key] = convert_date(combined.get(date_key))
            
            save_to_csv(combined)
            
            if (idx + 1) % 50 == 0:
                print(f"ğŸ’¾ ì§„í–‰ ìƒí™©: {idx + 1} / {len(all_courses)}")
            time.sleep(0.1)
            
        except Exception as e:
            print(f"âš ï¸ ìƒì„¸ ì‹¤íŒ¨ (ID: {course_id}): {e}")
            save_to_csv(item)
            continue

    print(f"\nâœ¨ ìˆ˜ì§‘ ì™„ë£Œ! íŒŒì¼ëª…: {SAVE_FILENAME}")

if __name__ == "__main__":
    main()
