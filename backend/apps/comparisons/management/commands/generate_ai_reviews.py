# apps/comparisons/management/commands/generate_ai_reviews.py

import os
import json
import time
import requests
import csv
from django.core.management.base import BaseCommand, CommandError
from django.db import transaction
from django.conf import settings
from apps.courses.models import Course
from apps.comparisons.models import CourseAIReview

"""
[ì„¤ê³„ì˜ë„]
- ëª¨ë“  ê°•ì¢Œ(Course)ì— ëŒ€í•´ LLM ê¸°ë°˜ì˜ 'AI í‰ê°€(CourseAIReview)'ë¥¼ ìƒì„±/ì €ì¥í•˜ëŠ” Django management command
- í…ŒìŠ¤íŠ¸/ìš´ì˜ ìƒí™©ì— ë§ê²Œ ì²˜ë¦¬ ë²”ìœ„ë¥¼ ì œì–´(--limit, --course-id)í•˜ê³ ,
  ì¬ìƒì„± ì •ì±…ì„ ì„ íƒ(--force)í•˜ë©°,
  í˜¸ì¶œ ì†ë„ ì œí•œ(--delay)ìœ¼ë¡œ API Rate Limitì„ í”¼í•˜ë„ë¡ ì„¤ê³„

[ìƒì„¸ ê³ ë ¤ì‚¬í•­]
- API í‚¤ëŠ” ì½”ë“œì— í•˜ë“œì½”ë”©í•˜ì§€ ì•Šê³  í™˜ê²½ë³€ìˆ˜(GMS_KEY)ë¡œ ì£¼ì…í•˜ì—¬ ë³´ì•ˆ/ìš´ì˜ í¸ì˜ì„±ì„ í™•ë³´
- ì´ë¯¸ í‰ê°€ê°€ ì¡´ì¬í•˜ëŠ” ê°•ì¢ŒëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ìŠ¤í‚µ(ai_review__isnull=True)í•˜ì—¬ ë¹„ìš©/ì‹œê°„ì„ ì ˆê°
  (ë‹¨, --force ì˜µì…˜ì´ë©´ update_or_createë¡œ ë®ì–´ì“°ê¸°)
- ê° ê°•ì¢Œë³„ DB ì €ì¥ì€ transaction.atomic()ìœ¼ë¡œ ê°ì‹¸
  ë¶€ë¶„ ì €ì¥/ë¶ˆì™„ì „ ì €ì¥ì„ ë°©ì§€í•˜ê³  ì›ìì„±ì„ í™•ë³´
- ì‹¤íŒ¨í•œ ê°•ì¢ŒëŠ” ì „ì²´ ì‘ì—…ì„ ì¤‘ë‹¨í•˜ì§€ ì•Šê³  continueë¡œ ë„˜ì–´ê°€
  "ëŒ€ëŸ‰ ì²˜ë¦¬ ë°°ì¹˜ ì‘ì—…"ì—ì„œ í”í•œ ë¶€ë¶„ ì‹¤íŒ¨ í—ˆìš© ì „ëµ ì ìš©
- LLM ì‘ë‹µì€ JSON ëª¨ë“œ(response_format=json_object)ë¥¼ ì‚¬ìš©í•˜ê³ ,
  ì¶”ê°€ë¡œ json.loads + í•„ìˆ˜ í•„ë“œ/ì ìˆ˜ ë²”ìœ„ ê²€ì¦ì„ í†µí•´ ë°ì´í„° í’ˆì§ˆì„ ë°©ì–´
- ìƒì„±ëœ ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ë‚´ë³´ë‚¼ ìˆ˜ ìˆëŠ” ê¸°ëŠ¥ ì¶”ê°€ (--output)
"""

MODEL_VERSION = 'gpt-4o-mini'
PROMPT_VERSION = 'v2.1'

class Command(BaseCommand):
    help = 'LLMì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë“  ê°•ì¢Œì— ëŒ€í•œ AI í‰ê°€ ìƒì„±'

    # í´ë˜ìŠ¤ ìƒìˆ˜ - ì¤‘ë³µ ì œê±° ë° ìœ ì§€ë³´ìˆ˜ì„± í–¥ìƒ
    # LLMì´ í‰ê°€í•˜ëŠ” í•„ë“œ (durationì€ ì½”ë“œë¡œ ì§ì ‘ ê³„ì‚°)
    LLM_RATING_FIELDS = [
        'theory_rating',
        'practical_rating',
        'difficulty_rating',
    ]

    # ì „ì²´ rating í•„ë“œ (í‰ê·  ê³„ì‚°ì— ì‚¬ìš©)
    RATING_FIELDS = LLM_RATING_FIELDS + ['duration_rating']

    REQUIRED_FIELDS = ['course_summary'] + LLM_RATING_FIELDS

    # CourseAIReview ëª¨ë¸ì˜ course_summary í•„ë“œ max_length ê¸°ì¤€
    SUMMARY_MAX_LENGTH = 999

    # ë°°ì¹˜ ì„¤ì •
    CSV_BATCH_SIZE = 50  # CSV ì¤‘ê°„ ì €ì¥ ê°„ê²©

    # LLM ì„¤ì •
    LLM_TEMPERATURE = 0.3  # ì¼ê´€ëœ í‰ê°€ë¥¼ ìœ„í•´ ë‚®ì€ temperature
    LLM_MAX_TOKENS = 800   # ì¶©ë¶„í•œ ì‘ë‹µ ìƒì„±ì„ ìœ„í•œ í† í° ìˆ˜

    # CSV í•„ë“œ ìˆœì„œ ê³ ì • (í—¤ë” ì¼ê´€ì„± ë³´ì¥)
    CSV_FIELDNAMES = [
        'course_id',
        'course_name',
        'course_summary',
        'average_rating',
        'theory_rating',
        'practical_rating',
        'difficulty_rating',
        'duration_rating',
        'reason_theory',
        'reason_practical',
        'reason_difficulty',
        'reason_duration',
    ]

    def add_arguments(self, parser):
        """
        [ì„¤ê³„ì˜ë„]
        - ë°°ì¹˜ ì‘ì—…ì—ì„œ í”íˆ í•„ìš”í•œ "ë²”ìœ„ ì œì–´/ì¬ì‹¤í–‰ ì •ì±…/ì†ë„ ì œí•œ"ì„ CLI ì˜µì…˜ìœ¼ë¡œ ì œê³µ

        [ìƒì„¸ ê³ ë ¤ì‚¬í•­]
        - --limit: ê°œë°œ/í…ŒìŠ¤íŠ¸ ì‹œ ì¼ë¶€ë§Œ ëŒë ¤ ë¹ ë¥´ê²Œ ê²€ì¦í•  ìˆ˜ ìˆë„ë¡ í•¨
        - --force: ì´ë¯¸ í‰ê°€ê°€ ìˆì–´ë„ ë‹¤ì‹œ ìƒì„±(ì—…ë°ì´íŠ¸)í•  ìˆ˜ ìˆë„ë¡ í•¨
        - --course-id: íŠ¹ì • ê°•ì¢Œ 1ê°œë§Œ ëŒ€ìƒìœ¼ë¡œ ë””ë²„ê¹…/í…ŒìŠ¤íŠ¸ ê°€ëŠ¥
        - --delay: API rate limit ë° ì„œë²„ ë¶€í•˜ ì™„í™”ë¥¼ ìœ„í•´ í˜¸ì¶œ ê°„ sleep ì œì–´
        - --output: ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥í•  íŒŒì¼ëª… (data/backups/ í•˜ìœ„ì— ìƒì„±)
        """
        parser.add_argument(
            '--limit',
            type=int,
            default=None,
            help='ì²˜ë¦¬í•  ê°•ì¢Œ ìˆ˜ ì œí•œ (í…ŒìŠ¤íŠ¸ìš©)'
        )
        parser.add_argument(
            '--force',
            action='store_true',
            help='ì´ë¯¸ í‰ê°€ê°€ ìˆëŠ” ê°•ì¢Œë„ ì¬ìƒì„±'
        )
        parser.add_argument(
            '--course-id',
            type=int,
            default=None,
            help='íŠ¹ì • ê°•ì¢Œë§Œ í‰ê°€ (í…ŒìŠ¤íŠ¸ìš©)'
        )
        parser.add_argument(
            '--delay',
            type=float,
            default=0.5,
            help='API í˜¸ì¶œ ê°„ ëŒ€ê¸° ì‹œê°„ (ì´ˆ)'
        )
        parser.add_argument(
            '--output',
            type=str,
            default=None,
            help='ê²°ê³¼ë¥¼ ì €ì¥í•  CSV íŒŒì¼ëª… (ì˜ˆ: ai_reviews_backup.csv)'
        )

    def handle(self, *args, **options):
        """
        [ì„¤ê³„ì˜ë„]
        - ì»¤ë§¨ë“œ ì‹¤í–‰ ì‹œ ì „ì²´ ì œì–´ íë¦„(ì„¤ì • â†’ ëŒ€ìƒ ì¶”ì¶œ â†’ ë°˜ë³µ ì²˜ë¦¬ â†’ ê²°ê³¼ ìš”ì•½)ì„ ë‹´ë‹¹í•˜ëŠ” ì—”íŠ¸ë¦¬í¬ì¸íŠ¸

        [ìƒì„¸ ê³ ë ¤ì‚¬í•­]
        - stdoutì— ì§„í–‰ë¥ /ì„±ê³µ/ì‹¤íŒ¨ë¥¼ ì¶œë ¥í•´ ë°°ì¹˜ ì‹¤í–‰ ë¡œê·¸ë¡œ í™œìš© ê°€ëŠ¥
        - ê°•ì¢Œ ë‹¨ìœ„ë¡œ try/except ì²˜ë¦¬í•˜ì—¬ ì¼ë¶€ ì‹¤íŒ¨ê°€ ì „ì²´ë¥¼ ì¤‘ë‹¨ì‹œí‚¤ì§€ ì•Šë„ë¡ í•¨
        """
        self.stdout.write(self.style.SUCCESS('=' * 70))
        self.stdout.write(self.style.SUCCESS('ê°•ì¢Œ AI í‰ê°€ ìƒì„± ì‹œì‘'))
        self.stdout.write(self.style.SUCCESS('=' * 70))

        # =============================================
        # 1. GMS API ì„¤ì •
        # =============================================
        gms_url = "https://gms.ssafy.io/gmsapi/api.openai.com/v1/chat/completions"
        gms_key = os.environ.get("GMS_KEY")

        if not gms_key:
            raise CommandError('GMS_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.')

        # =============================================
        # 2. ì²˜ë¦¬í•  ê°•ì¢Œ í•„í„°ë§
        # =============================================
        if options['course_id']:
            courses = Course.objects.filter(id=options['course_id'])
            if not courses.exists():
                raise CommandError(f"ID {options['course_id']} ê°•ì¢Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        elif options['force']:
            courses = Course.objects.all()
        else:
            courses = Course.objects.filter(ai_review__isnull=True)

        if options['limit']:
            courses = courses[:options['limit']]

        total_count = courses.count()

        if total_count == 0:
            self.stdout.write(self.style.SUCCESS('ì²˜ë¦¬í•  ê°•ì¢Œê°€ ì—†ìŠµë‹ˆë‹¤.'))
            return

        self.stdout.write(f'\nì´ {total_count}ê°œ ê°•ì¢Œ ì²˜ë¦¬ ì‹œì‘\n')

        # =============================================
        # 3. í†µê³„ ë° íŒŒì¼ ì„¤ì • ë³€ìˆ˜
        # =============================================
        success_count = 0
        error_count = 0
        batch_results = []

        output_path = None
        if options['output']:
            project_root = settings.BASE_DIR.parent
            backup_dir = os.path.join(project_root, 'data', 'backups')
            os.makedirs(backup_dir, exist_ok=True)
            output_path = os.path.join(backup_dir, options['output'])

        # =============================================
        # 4. ê° ê°•ì¢Œ ì²˜ë¦¬
        # =============================================
        for idx, course in enumerate(courses, 1):
            self.stdout.write(f'\n[{idx}/{total_count}] ì²˜ë¦¬ ì¤‘: {course.name} (ID: {course.id})')

            try:
                # LLM í˜¸ì¶œí•˜ì—¬ AI í‰ê°€ ìƒì„±
                ai_review_data = self._generate_ai_review(course, gms_url, gms_key)

                # DB ì €ì¥
                with transaction.atomic():
                    review_data = self._prepare_review_data(ai_review_data)
                    review_data.update({
                        'model_version': MODEL_VERSION,
                        'prompt_version': PROMPT_VERSION
                    })

                    ai_review, created = CourseAIReview.objects.update_or_create(
                        course=course,
                        defaults=review_data
                    )

                # CSVìš© ë°ì´í„° ìˆ˜ì§‘
                if output_path:
                    csv_data = self._prepare_csv_data(course, ai_review_data)
                    batch_results.append(csv_data)

                action = 'ìƒì„±' if created else 'ì—…ë°ì´íŠ¸'
                self.stdout.write(
                    self.style.SUCCESS(
                        f'  âœ“ {action} ì™„ë£Œ - ì¢…í•©: {ai_review_data["average_rating"]}/5'
                    )
                )

                success_count += 1

                # ì¤‘ê°„ ì €ì¥
                if output_path and len(batch_results) >= self.CSV_BATCH_SIZE:
                    self._save_to_csv(output_path, batch_results)
                    self.stdout.write(self.style.WARNING(f'  ğŸ’¾ ì¤‘ê°„ ì €ì¥ ì™„ë£Œ ({success_count}ê°œ)'))
                    batch_results = []

                # Rate Limiting
                if idx < total_count:
                    time.sleep(options['delay'])

            except Exception as e:
                error_count += 1
                self.stdout.write(self.style.ERROR(f'  âœ— ì—ëŸ¬ ë°œìƒ: {str(e)}'))
                continue

        # =============================================
        # 5. ë‚¨ì€ ì”ì—¬ ë°ì´í„° ì €ì¥
        # =============================================
        if output_path and batch_results:
            self._save_to_csv(output_path, batch_results)
            self.stdout.write(self.style.SUCCESS(f'\nâœ“ ìµœì¢… CSV ì €ì¥ ì™„ë£Œ: {output_path}'))

        # 6. ê²°ê³¼ ìš”ì•½
        self.stdout.write('\n' + '=' * 70)
        self.stdout.write(self.style.SUCCESS('ì‘ì—… ì™„ë£Œ'))
        self.stdout.write('=' * 70)
        self.stdout.write(f'âœ“ ì„±ê³µ: {success_count}ê°œ')
        self.stdout.write(f'âœ— ì‹¤íŒ¨: {error_count}ê°œ')
        if options['output']:
            self.stdout.write(f'ğŸ“ íŒŒì¼: {options["output"]}')
        self.stdout.write(f'ì´ ì²˜ë¦¬: {success_count + error_count}ê°œ\n')

    def _calculate_duration_rating(self, week):
        """
        ì£¼ì°¨ ìˆ˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•™ìŠµ ê¸°ê°„ í‰ì  ê³„ì‚°

        Args:
            week: ê°•ì¢Œ ì£¼ì°¨ ìˆ˜

        Returns:
            int: 1-5 ë²”ìœ„ì˜ í•™ìŠµ ê¸°ê°„ í‰ì 
        """
        if not week:
            return 3  # ê¸°ë³¸ê°’: ì¤‘ê°„

        if week <= 4:
            return 1
        elif week <= 8:
            return 2
        elif week <= 12:
            return 3
        elif week <= 16:
            return 4
        else:
            return 5

    def _prepare_review_data(self, ai_review_data):
        """
        AI ë¦¬ë·° ë°ì´í„°ë¥¼ DB ì €ì¥ í˜•ì‹ìœ¼ë¡œ ë³€í™˜

        Args:
            ai_review_data: LLMìœ¼ë¡œë¶€í„° ë°›ì€ í‰ê°€ ë°ì´í„°

        Returns:
            dict: DB ì €ì¥ìš© ë°ì´í„°
        """
        data = {
            'course_summary': ai_review_data['course_summary'][:self.SUMMARY_MAX_LENGTH],
            'average_rating': ai_review_data['average_rating'],
        }

        # Rating í•„ë“œ ì¶”ê°€
        for field in self.RATING_FIELDS:
            data[field] = ai_review_data[field]

        return data

    def _prepare_csv_data(self, course, ai_review_data):
        """
        AI ë¦¬ë·° ë°ì´í„°ë¥¼ CSV ì €ì¥ í˜•ì‹ìœ¼ë¡œ ë³€í™˜

        Args:
            course: Course ì¸ìŠ¤í„´ìŠ¤
            ai_review_data: LLMìœ¼ë¡œë¶€í„° ë°›ì€ í‰ê°€ ë°ì´í„°

        Returns:
            dict: CSV ì €ì¥ìš© ë°ì´í„°
        """
        csv_data = {
            'course_id': course.id,
            'course_name': course.name,
            'course_summary': ai_review_data['course_summary'],
            'average_rating': ai_review_data['average_rating'],
        }

        # Rating í•„ë“œ ì¶”ê°€
        for field in self.RATING_FIELDS:
            csv_data[field] = ai_review_data[field]

        # Reasoning í•„ë“œ ì¶”ê°€ (ì„ íƒì‚¬í•­)
        reasoning = ai_review_data.get('reasoning', {})
        csv_data.update({
            'reason_theory': reasoning.get('theory', ''),
            'reason_practical': reasoning.get('practical', ''),
            'reason_difficulty': reasoning.get('difficulty', ''),
            'reason_duration': '',  # Durationì€ ì½”ë“œë¡œ ê³„ì‚°í•˜ë¯€ë¡œ reasoning ì—†ìŒ
        })

        return csv_data

    def _save_to_csv(self, file_path, data_list):
        """
        ë°ì´í„° ë¦¬ìŠ¤íŠ¸ë¥¼ CSV íŒŒì¼ì— ì¶”ê°€ ì €ì¥

        Args:
            file_path: ì €ì¥í•  íŒŒì¼ ê²½ë¡œ
            data_list: ì €ì¥í•  ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        """
        if not data_list:
            return

        file_exists = os.path.isfile(file_path)
        with open(file_path, 'a', encoding='utf-8-sig', newline='') as f:
            writer = csv.DictWriter(f, fieldnames=self.CSV_FIELDNAMES)
            if not file_exists:
                writer.writeheader()
            writer.writerows(data_list)

    def _generate_ai_review(self, course, gms_url, gms_key):
        """
        LLMì„ í˜¸ì¶œí•˜ì—¬ ê°•ì¢Œ í‰ê°€ ìƒì„± (ë©”ì¸ ë¡œì§)

        Args:
            course: Course ì¸ìŠ¤í„´ìŠ¤
            gms_url: GMS API URL
            gms_key: GMS API í‚¤

        Returns:
            dict: AI í‰ê°€ ë°ì´í„°
        """
        system_prompt, user_prompt = self._build_prompts(course)
        response_data = self._call_gms_api(gms_url, gms_key, system_prompt, user_prompt)
        ai_review = self._parse_and_validate_response(response_data)

        # Duration ratingì„ ì½”ë“œë¡œ ì§ì ‘ ê³„ì‚°í•˜ì—¬ ì¶”ê°€
        ai_review['duration_rating'] = self._calculate_duration_rating(course.week)

        # Duration í¬í•¨í•˜ì—¬ í‰ê·  ì¬ê³„ì‚°
        total_rating = sum(ai_review[field] for field in self.RATING_FIELDS)
        ai_review['average_rating'] = round(total_rating / len(self.RATING_FIELDS), 2)

        return ai_review

    def _build_prompts(self, course):
        """
        ê°•ì¢Œ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ System/User í”„ë¡¬í”„íŠ¸ ìƒì„±

        Args:
            course: Course ì¸ìŠ¤í„´ìŠ¤

        Returns:
            tuple: (system_prompt, user_prompt)
        """
        # ë°ì´í„° ì „ì²˜ë¦¬: ì´ˆ ë‹¨ìœ„ë¥¼ ì‹œê°„ ë‹¨ìœ„ë¡œ ë³€í™˜
        total_playtime_hours = round(course.course_playtime / 3600.0, 1) if course.course_playtime else 0

        system_prompt = """ë‹¹ì‹ ì€ K-MOOC ì˜¨ë¼ì¸ ê°•ì¢Œ í‰ê°€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì£¼ì–´ì§„ ê°•ì¢Œ ì •ë³´ë¥¼ ë¶„ì„í•˜ì—¬ ê°ê´€ì ì´ê³  ì¼ê´€ëœ í‰ê°€ë¥¼ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.

í‰ê°€ ê¸°ì¤€ (ëª¨ë“  í•­ëª©ì€ 1-5 ë²”ìœ„ì˜ ì •ìˆ˜):
1. ì´ë¡ ì  ê¹Šì´ (theory_rating): ê°œë…ê³¼ ì›ë¦¬ì˜ ê¹Šì´
   - 1-2: ë§¤ìš° ê¸°ì´ˆì , ê°œë… ì†Œê°œ ìˆ˜ì¤€
   - 3: ì¤‘ê¸‰, ì›ë¦¬ì™€ ê°œë… ì„¤ëª…
   - 4-5: ê³ ê¸‰, ì‹¬í™” ì´ë¡  ë° ìˆ˜í•™ì  ì¦ëª… í¬í•¨

2. ì‹¤ë¬´ì  í™œìš©ë„ (practical_rating): ì‹¤ë¬´ ì ìš© ê°€ëŠ¥ì„±
   - 1-2: ì´ë¡  ì¤‘ì‹¬, ì‹¤ìŠµ ê±°ì˜ ì—†ìŒ
   - 3: ê¸°ë³¸ ì‹¤ìŠµ í¬í•¨
   - 4-5: í”„ë¡œì íŠ¸ ì¤‘ì‹¬, í¬íŠ¸í´ë¦¬ì˜¤ ì œì‘ ê°€ëŠ¥

3. í•™ìŠµ ë‚œì´ë„ (difficulty_rating): í•™ìŠµì ìš”êµ¬ ìˆ˜ì¤€
   - 1-2: ì…ë¬¸ììš©, ë¹„ì „ê³µì ê°€ëŠ¥
   - 3: ì¤‘ê¸‰, ê¸°ë³¸ ì§€ì‹ í•„ìš”
   - 4-5: ê³ ê¸‰, ì „ë¬¸ ì§€ì‹ í•„ìˆ˜"""

        user_prompt = f"""ë‹¤ìŒ K-MOOC ê°•ì¢Œë¥¼ ë¶„ì„í•˜ì—¬ í‰ê°€í•´ì£¼ì„¸ìš”:

**ê°•ì¢Œ ê¸°ë³¸ ì •ë³´**
- ê°•ì¢Œëª…: {course.name}
- ìš´ì˜ ê¸°ê´€: {course.org_name or 'N/A'}
- êµìˆ˜ì: {course.professor or 'N/A'}
- ë¶„ë¥˜: {course.classfy_name} > {course.middle_classfy_name}

**ê°•ì¢Œ ê·œëª¨**
- ì£¼ì°¨ ìˆ˜: {course.week or 'N/A'}ì£¼
- ì´ ì˜ìƒ ì‹œê°„: {total_playtime_hours}ì‹œê°„

**ê°•ì¢Œ ì„¤ëª…**
{course.summary or 'ì„¤ëª… ì—†ìŒ'}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ í‰ê°€ë¥¼ ì œê³µí•˜ì„¸ìš”:
{{
  "course_summary": "ê°•ì¢Œì˜ í•µì‹¬ ë‚´ìš©ê³¼ í•™ìŠµ ëª©í‘œë¥¼ 2-3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½",
  "theory_rating": 3,
  "practical_rating": 2,
  "difficulty_rating": 3,
  "reasoning": {{
    "theory": "ì´ë¡  ì ìˆ˜ ê·¼ê±° (1ë¬¸ì¥)",
    "practical": "ì‹¤ë¬´ ì ìˆ˜ ê·¼ê±° (1ë¬¸ì¥)",
    "difficulty": "ë‚œì´ë„ ì ìˆ˜ ê·¼ê±° (1ë¬¸ì¥)"
  }}
}}

ì°¸ê³ : ëª¨ë“  rating ê°’ì€ 1-5 ë²”ìœ„ì˜ ì •ìˆ˜ì—¬ì•¼ í•©ë‹ˆë‹¤."""

        return system_prompt, user_prompt

    def _call_gms_api(self, gms_url, gms_key, system_prompt, user_prompt):
        """
        GMS APIë¥¼ í˜¸ì¶œí•˜ì—¬ LLM ì‘ë‹µ ë°›ê¸°

        Args:
            gms_url: GMS API URL
            gms_key: GMS API í‚¤
            system_prompt: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
            user_prompt: ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸

        Returns:
            dict: API ì‘ë‹µ ë°ì´í„°

        Raises:
            Exception: API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ
        """
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {gms_key}"
        }

        data = {
            "model": MODEL_VERSION,
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            "response_format": {"type": "json_object"},
            "temperature": self.LLM_TEMPERATURE,
            "max_tokens": self.LLM_MAX_TOKENS
        }

        response = requests.post(
            gms_url,
            headers=headers,
            data=json.dumps(data),
            timeout=30
        )

        if response.status_code != 200:
            raise Exception(
                f"GMS API í˜¸ì¶œ ì‹¤íŒ¨ (Status: {response.status_code}): {response.text[:200]}"
            )

        return response.json()

    def _parse_and_validate_response(self, response_data):
        """
        LLM ì‘ë‹µì„ íŒŒì‹±í•˜ê³  ê²€ì¦

        Args:
            response_data: API ì‘ë‹µ ë°ì´í„°

        Returns:
            dict: ê²€ì¦ëœ AI í‰ê°€ ë°ì´í„°

        Raises:
            Exception: íŒŒì‹± ì‹¤íŒ¨ ë˜ëŠ” ê²€ì¦ ì‹¤íŒ¨ ì‹œ
        """
        content = response_data['choices'][0]['message']['content']

        # JSON íŒŒì‹±
        try:
            ai_review = json.loads(content)
        except json.JSONDecodeError as e:
            raise Exception(f"JSON íŒŒì‹± ì‹¤íŒ¨: {content[:200]}...")

        # í•„ìˆ˜ í•„ë“œ ê²€ì¦
        for field in self.REQUIRED_FIELDS:
            if field not in ai_review:
                raise Exception(f"í•„ìˆ˜ í•„ë“œ ëˆ„ë½: {field}")

        # LLMì´ ìƒì„±í•œ ì ìˆ˜ ë²”ìœ„ ê²€ì¦
        for field in self.LLM_RATING_FIELDS:
            value = ai_review[field]
            if not isinstance(value, int) or value < 1 or value > 5:
                raise Exception(
                    f"{field} ê°’ì´ ìœ íš¨í•˜ì§€ ì•ŠìŒ: {value} (1-5 ì‚¬ì´ì˜ ì •ìˆ˜ì—¬ì•¼ í•¨)"
                )

        return ai_review
